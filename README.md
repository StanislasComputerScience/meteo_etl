# meteo_etl# ğŸŒ¤ï¸ MÃ©tÃ©o ETL â€“ Pipeline de DonnÃ©es MÃ©tÃ©o pour quelques Villes FranÃ§aises

Ce projet implÃ©mente un pipeline **ETL (Extract, Transform, Load)** en Python permettant de rÃ©cupÃ©rer, nettoyer et stocker les prÃ©visions mÃ©tÃ©o horaires pour les principales villes franÃ§aises. Il combine des technologies modernes pour le traitement et la gestion de donnÃ©es.

---

## ğŸš€ Objectifs du Projet

- Collecter automatiquement les prÃ©visions mÃ©tÃ©o depuis une API externe (MÃ©tÃ©o Concept).
- Nettoyer et structurer les donnÃ©es mÃ©tÃ©o (tempÃ©rature, humiditÃ©, vent, etc.).
- Stocker les donnÃ©es :
  - En **MongoDB** pour les donnÃ©es brutes.
  - En **PostgreSQL** pour les donnÃ©es nettoyÃ©es.

- Permettre des requÃªtes et analyses sur les donnÃ©es consolidÃ©es.

---

## ğŸ› ï¸ Stack Technique

| Composant     | Utilisation                          |
|---------------|--------------------------------------|
| Python        | Logique ETL                          |
| Requests      | RequÃªte API                          |
| PostgreSQL    | Stockage des donnÃ©es nettoyÃ©es       |
| Psycopg2      | Connexion PostgreSQL                 |
| Dotenv        | Gestion des variables dâ€™environnement|

---

## ğŸ“¦ Structure du Projet

meteo_etl/
â”œâ”€â”€ config/ # Fichier .env
â”œâ”€â”€ extract/ # Scripts d'extraction API
â”‚ â””â”€â”€ fetch.py
â”œâ”€â”€ transform/ # Nettoyage et normalisation
â”‚ â””â”€â”€ clean_data.py
â”œâ”€â”€ load/ # Insertion dans les bases de donnÃ©es
â”‚ â””â”€â”€ insert_to_db.py
â”œâ”€â”€ read_data.py # Script pour lire les donnÃ©es depuis PostgreSQL
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md



Ã  venir :
- Orchestration du pipeline avec **Apache Airflow** (en local).

| Pandas        | Transformation des donnÃ©es           |
| MongoDB       | Stockage des donnÃ©es brutes          |
| Airflow       | Orchestration du pipeline            |

â”œâ”€â”€ airflow_dags/ # DAGs pour Airflow