# ğŸŒ¤ï¸ MÃ©tÃ©o ETL â€“ Pipeline de DonnÃ©es MÃ©tÃ©o pour quelques Villes FranÃ§aises

Ce projet implÃ©mente un pipeline **ETL (Extract, Transform, Load)** en Python permettant de rÃ©cupÃ©rer, nettoyer et stocker les prÃ©visions mÃ©tÃ©o horaires pour plusieurs villes franÃ§aises. Il combine des outils modernes pour le traitement, l'orchestration et la visualisation de donnÃ©es.

---

## ğŸš€ Objectifs du Projet

- âœ… **Collecter automatiquement** les prÃ©visions mÃ©tÃ©o via l'API MÃ©tÃ©o Concept.
- âœ… **Nettoyer et structurer** les donnÃ©es (tempÃ©rature, humiditÃ©, vent, etc.).
- âœ… **Stocker les donnÃ©es** :
  - En **PostgreSQL** pour les donnÃ©es nettoyÃ©es.
- âœ… **Visualiser** les donnÃ©es dans une interface interactive avec Streamlit.
- ğŸ”œ **Orchestrer** automatiquement le pipeline avec Airflow.

---

## ğŸ› ï¸ Stack Technique

| Composant      | RÃ´le                                      |
|----------------|-------------------------------------------|
| Python         | Langage principal                         |
| Requests       | Appels Ã  l'API mÃ©tÃ©o                      |
| Pandas         | Traitement et nettoyage des donnÃ©es       |
| PostgreSQL     | Stockage des donnÃ©es nettoyÃ©es            |
| Psycopg2       | Connexion PostgreSQL                      |
| Streamlit      | Visualisation interactive                 |
| Airflow        | Orchestration du pipeline ETL (Ã  venir)   |
| Dotenv         | Gestion des variables dâ€™environnement     |

---

## ğŸ“ Structure du projet

```text
meteo_etl/
â”œâ”€â”€ airflow_dags/           # ğŸ”œ DAGs Airflow (pipeline automatique)
â”œâ”€â”€ config/
â”‚   â””â”€â”€ .env                # Token API, INSEE code, credentials
â”œâ”€â”€ data/
â”‚   â””â”€â”€ create_tables_data.py   # CrÃ©ation des tables PostgreSQL
â”œâ”€â”€ extract/
â”‚   â””â”€â”€ fetch_data.py       # RÃ©cupÃ©ration via API MÃ©tÃ©o Concept
â”œâ”€â”€ transform/
â”‚   â””â”€â”€ clean_data.py       # Nettoyage et formatage des donnÃ©es
â”œâ”€â”€ load/
â”‚   â””â”€â”€ insert_to_db.py     # Insertion dans la base PostgreSQL
â”œâ”€â”€ visualise.py            # Interface Streamlit pour explorer les donnÃ©es
â”œâ”€â”€ read_data.py            # Lecture simple depuis PostgreSQL
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â””â”€â”€ README.md               # Documentation du projet


## âš™ï¸ Utilisation

### 1. Configuration

CrÃ©er un fichier `.env` dans le dossier `config/` :

```env
API_TOKEN=your_api_token_here
INSEE_CODE=75056
DB_NAME=meteo
DB_USER=meteo_user
DB_PASSWORD=meteo123
DB_HOST=localhost

### 2. Installation des dÃ©pendances
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

### 3. Lancer le pipeline ETL manuellement
python load/insert_to_db.py

### 4. Lancer Aiflow
./run_airflow.sh

### ğŸ“Š Exemple de Visualisation
Lâ€™interface Streamlit permet de :

SÃ©lectionner une station mÃ©tÃ©o

Afficher les tempÃ©ratures horaires

Explorer les humiditÃ©s, vents, pressions, etc.

Visualiser les donnÃ©es brutes sous forme de tableau

### ğŸ§‘â€ğŸ’» Auteur
Projet rÃ©alisÃ© par RÃ©mi LABONNE

### ğŸ“„ Licence
Ce projet est open-source, sous licence MIT.
